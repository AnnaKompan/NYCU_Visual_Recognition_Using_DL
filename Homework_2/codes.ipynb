{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26c2966",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "import torch\n",
    "import torchvision\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.models.detection.rpn import AnchorGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26f1d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "import torch\n",
    "import torchvision\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.models.detection.rpn import AnchorGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2aa607",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a948b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HW2Data(Dataset):\n",
    "    def __init__(self, img_root, json_path=''):\n",
    "        super().__init__()\n",
    "        self.mode = img_root.split('/')[-1]\n",
    "        self.img_root = img_root\n",
    "        self.preprocess = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "        if self.mode != 'test':\n",
    "            with open(json_path, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "                self.img_list = data['images']\n",
    "                self.anno_list = data['annotations']\n",
    "                self.cat_list = data['categories']\n",
    "        else:\n",
    "            self.img_list = glob.glob(f'{img_root}/*.png')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_list)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if self.mode != 'test':\n",
    "            img_id = self.img_list[index]['id']\n",
    "            img_path = f\"{self.img_root}/{self.img_list[index]['file_name']}\"\n",
    "            \n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "            img = self.preprocess(img)\n",
    "\n",
    "            annos = [anno for anno in self.anno_list if anno['image_id'] == img_id]\n",
    "            boxes = [\n",
    "                    [anno['bbox'][0], anno['bbox'][1], \n",
    "                     anno['bbox'][0]+anno['bbox'][2], anno['bbox'][1]+anno['bbox'][3]] \n",
    "                     for anno in annos\n",
    "                ]\n",
    "            labels = [anno['category_id'] for anno in annos]\n",
    "\n",
    "            target = {\n",
    "                \"boxes\": torch.tensor(boxes),\n",
    "                \"labels\": torch.tensor(labels)\n",
    "            }\n",
    "            return img, target\n",
    "        \n",
    "        img = Image.open(self.img_list[index]).convert('RGB')\n",
    "        img = self.preprocess(img)\n",
    "        return img, index+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0e50e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /Users/boan/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n",
      "100%|██████████| 97.8M/97.8M [00:11<00:00, 9.29MB/s]\n"
     ]
    }
   ],
   "source": [
    "backbone = torchvision.models.resnet50(weights=torchvision.models.ResNet50_Weights.DEFAULT)\n",
    "backbone = torch.nn.Sequential(*list(backbone.children())[:-2])\n",
    "backbone.out_channels = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d939f59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_generator = AnchorGenerator(\n",
    "    sizes=((16, 32, 64, 128, 256),),\n",
    "    aspect_ratios=((0.5, 1.0, 2.0),) * 5\n",
    ")\n",
    "roi_pooler = torchvision.ops.MultiScaleRoIAlign(\n",
    "    featmap_names=['0'],\n",
    "    output_size=7,\n",
    "    sampling_ratio=2\n",
    ")\n",
    "model = FasterRCNN(\n",
    "    backbone,\n",
    "    num_classes=11,\n",
    "    rpn_anchor_generator=anchor_generator,\n",
    "    box_roi_pool=roi_pooler\n",
    ")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8949cc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, data_loader, optimizer, num_epochs=5, device='cuda', checkpoint_dir='checkpoints'):\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "\n",
    "        pbar = tqdm(data_loader, desc=f\"[Train] Epoch {epoch+1}\")\n",
    "        for images, targets in pbar:\n",
    "            images = [images.to(device).squeeze(0)]\n",
    "            targets = [{\n",
    "                'boxes': targets['boxes'].to(device).squeeze(0),\n",
    "                'labels': targets['labels'].to(device).squeeze(0)\n",
    "            }]\n",
    "\n",
    "            loss_dict = model(images, targets)\n",
    "            loss = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            pbar.set_postfix(loss=total_loss / (pbar.n + 1))\n",
    "\n",
    "        avg_loss = total_loss / len(data_loader)\n",
    "        print(f\"Epoch {epoch+1}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "        os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f\"epoch_{epoch+1}.pth\")\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "        }, checkpoint_path)\n",
    "        print(f\"Checkpoint saved: {checkpoint_path}\")\n",
    "\n",
    "def evaluate_model(model, data_loader, device='cuda', output_file='pred.json'):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    results = []\n",
    "    with torch.no_grad():\n",
    "        for images, image_ids in data_loader:\n",
    "            images = [img.to(device) for img in images]\n",
    "            outputs = model(images)\n",
    "            \n",
    "            for img_id, output in zip(image_ids, outputs):\n",
    "                result = {\n",
    "                    'image_id': int(img_id),  \n",
    "                    'bbox': [box.tolist() for box in output['boxes'].cpu()],\n",
    "                    'score': [float(s) for s in output['scores'].cpu()],\n",
    "                    'category_id': [int(c) for c in output['labels'].cpu()],\n",
    "                }\n",
    "                results.append(result)\n",
    "    \n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(results, f, indent=4)\n",
    "    print(f\"Evaluation results saved to {output_file}\")\n",
    "\n",
    "\n",
    "def load_checkpoint(model, optimizer, checkpoint_path):\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    print(f\"Checkpoint loaded: {checkpoint_path}, Starting from epoch {start_epoch}\")\n",
    "    return start_epoch\n",
    "\n",
    "# Now 3\n",
    "def save_checkpoint(model, optimizer, epoch, checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    checkpoint_path = os.path.join(checkpoint_dir, f\"epoch_{epoch+1}.pth\")\n",
    "    torch.save({\n",
    "        'epoch': epoch + 1,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "    }, checkpoint_path)\n",
    "    print(f\"Checkpoint saved: {checkpoint_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90908b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    HW2Data('./nycu-hw2-data/train', './nycu-hw2-data/train.json'), \n",
    "    batch_size=1, \n",
    "    shuffle=True, \n",
    "    num_workers=0, \n",
    "    pin_memory=True\n",
    ")\n",
    "train_model(model, train_loader, num_epochs=5, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56c23b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_loader = DataLoader(\n",
    "    HW2Data('./nycu-hw2-data/valid', './nycu-hw2-data/valid.json'), \n",
    "    batch_size=1, \n",
    "    shuffle=True, \n",
    "    num_workers=0, \n",
    "    pin_memory=True\n",
    ")\n",
    "def validate_model(model, data_loader, device='cuda'):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    total_val_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        val_pbar = tqdm(data_loader, desc='[Validation]')\n",
    "        for images, targets in val_pbar:\n",
    "            images = [img.to(device) for img in images]\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "            loss_dict = model(images, targets)\n",
    "            loss = sum(loss for loss in loss_dict.values())\n",
    "            total_val_loss += loss.item()\n",
    "\n",
    "            val_pbar.set_postfix(val_loss=total_val_loss / (val_pbar.n + 1))\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(data_loader)\n",
    "    print(f\"Validation Loss: {avg_val_loss:.4f}\")\n",
    "    return avg_val_loss\n",
    "\n",
    "validate_model(model, valid_loader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b933bd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = './checkpoints/epoch_5.pth'\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    HW2Data('./nycu-hw2-data/test'),\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "results = []\n",
    "score_threshold = 0.05\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, image_ids in test_loader:\n",
    "        images = [img.to(device) for img in images]\n",
    "        outputs = model(images)\n",
    "\n",
    "        for img_id, output in zip(image_ids, outputs):\n",
    "            boxes = output['boxes'].cpu()\n",
    "            scores = output['scores'].cpu()\n",
    "            labels = output['labels'].cpu()\n",
    "\n",
    "            for box, score, label in zip(boxes, scores, labels):\n",
    "                if score < 0.05:\n",
    "                    continue\n",
    "                x_min, y_min, x_max, y_max = box.tolist()\n",
    "                results.append({\n",
    "                    \"image_id\": int(img_id.item()),\n",
    "                    \"bbox\": [x_min, y_min, x_max - x_min, y_max - y_min],\n",
    "                    \"score\": float(score),\n",
    "                    \"category_id\": int(label)\n",
    "                })\n",
    "                \n",
    "                if len(results) < 5:\n",
    "                    print(\"Debug:\", results[-1])\n",
    "\n",
    "\n",
    "with open(\"pred.json\", \"w\") as f:\n",
    "    json.dump(results, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bef083c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pred.json') as f:\n",
    "    preds = json.load(f)\n",
    "\n",
    "image_predictions = {}\n",
    "\n",
    "for pred in preds:\n",
    "    image_id = pred[\"image_id\"]\n",
    "    category_id = pred[\"category_id\"]\n",
    "    x_min = pred[\"bbox\"][0]\n",
    "    score = pred[\"score\"]\n",
    "\n",
    "    if score < score_threshold:\n",
    "        continue\n",
    "\n",
    "    if image_id not in image_predictions:\n",
    "        image_predictions[image_id] = []\n",
    "\n",
    "    image_predictions[image_id].append((x_min, category_id))\n",
    "\n",
    "all_image_ids = list(range(1, 13069))\n",
    "result_rows = []\n",
    "\n",
    "for image_id in all_image_ids:\n",
    "    digits = image_predictions.get(image_id, [])\n",
    "\n",
    "    if not digits:\n",
    "        pred_label = -1\n",
    "    else:\n",
    "        digits.sort(key=lambda x: x[0])\n",
    "        try:\n",
    "            pred_label = int(''.join(str(d[1] - 1) for d in digits))\n",
    "        except ValueError:\n",
    "            pred_label = -1\n",
    "\n",
    "    result_rows.append({\"image_id\": image_id, \"pred_label\": pred_label})\n",
    "\n",
    "df = pd.DataFrame(result_rows)\n",
    "df.to_csv(\"pred.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-fenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
